---
title: Basic Concept
date: 2019-05-30 08:38:07
categories: 统计学习方法
tags: machine learning
mathjax: true
---
#### 机器学习中的一些基本概念
##### 贝叶斯学习
&emsp;&emsp;在概率模型的学习中, 利用贝叶斯定理, 计算后验概率,并进行模型估计, 对数据进行预测.将模型,未观测要素及其参数用变量表示.基本公式如下:
$$P(\theta |D)=\frac{P(\theta)P(D|\theta)}{P(D)}$$
&emsp;&emsp;其中$D$是数据, $\theta$是模型参数, $P(\theta)$是先验概率, $P(D|\theta)$是似然函数, $P(\theta |D)$是后验概率. 通常是取后验概率最大的模型.

<!--more-->

----
##### 经验风险最小化和结构风险最小化
&emsp;&emsp;在数据量足够大的时候,经验风险趋于期望风险,这时经验风险最小化就是求解模型最优化等价问题.
$$min_{f\in \mathcal{F}}\frac{1}{N}\sum^N_{i=1}L(y_i,f(x_i))$$
&emsp;&emsp;但是当样本量较小时,会存在过拟合现象.这时需要引入结构风险来防止过拟合.
$$min_{f\in \mathcal{F}}\frac{1}{N}\sum^N_{i=1}L(y_i,f(x_i))+\lambda J(f)$$
&emsp;&emsp;其中$J(f)$是模型复杂度,经典的方法是使用一个正则化项(如一范数,二范数),$\lambda$是用来权衡经验风险和模型复杂度的系数

&emsp;&emsp;极大似然估计是经验风险最小化的例子.也就是损失函数是对数损失函数时,极大似然估计等价于经验风险最小化；贝叶斯估计中的最大后验概率估计是结构风险最小化的例子.也就是损失函数是对数损失函数,模型复杂度由模型先验概率表示时,最大后验概率估计等价于结构风险最小化.

-----
##### 模型泛化
&emsp;&emsp;泛化误差实际上就是学习到模型的期望风险.泛化能力分析通常是求泛化误差上界.# Todo(公式推导)

-----
##### 生成模型和判别模型
&emsp;&emsp;生成模型是由数据学习联合概率分布$P(X,Y)$,然后求出条件概率分布$P(Y|X)$作为预测的模型.典型的生成模型有朴素贝叶斯和隐马尔可夫模型.
$$P(Y|X)=\frac{P(X,Y)}{P(X)}$$
&emsp;&emsp;判别模型是由数据直接学习决策函数$f(X)$或者条件概率分布$P(Y|X)$作为预测的模型.

&emsp;&emsp;显然生成模型关注输入$X$产生输出$Y$的生成关系,而判别模型关心给定输入$X$,应该预测什么样的输出$Y$；当样本容量增加时,生成模型的收敛速度更快；存在隐变量的时候,就只能使用生成模型；判别模型能够简化学习问题,对数据进行一定程度的抽象.

----
##### 评价指标
样本\预测 | 0 | 1
:---: | :---: | :---:
0 | TN | FP
1 | FN | TP

精确率(precision): $P=\frac{TP}{TP+FP}$

准确率(accuracy): $A=\frac{TP+TN}{TP+FP+FN+TN}$

召回率(recall): $R=\frac{TP}{TP+FN}$

F1值: $F_1=\frac{2PR}{P+R}=\frac{2TP}{2TP+FP+FN}$ 