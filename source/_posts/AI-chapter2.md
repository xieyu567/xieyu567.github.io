---
title: AI-chapter2
date: 2019-06-11 07:44:46
categories: AI-an answer of the modern method
visitors: 
mathjax: true
tags: AI
---
第二章的习题

#### 2.1
&emsp;&emsp;还是以扫地机为例子,如果之前的序列是扫地机一直向右走并清扫灰尘,但是当前已经到了墙角下,无法再向右走,如果扫地机只依赖于之前的时间步,那么就会一直停止.因此理性Agent的行动不仅依赖于环境状态,也要考虑它到达的时间点.

<!--more-->

#### 2.2
##### 1)
&emsp;&emsp;要证明这个扫地机是理性Agent,就是要证明对每个可能的感知序列,根据已知的感知序列提供的证据和Agent具有的先验知识,扫地机会选择能使其性能度量最大化的行动.先验知识是环境,也就是地板的分布.性能度量是每个时间步对每块清洁的方格奖励1分.因为只有左右两块地板,扫地机只具备向左,向右和打扫地面三个行动.按照之前的行动序列,可以认为这是能使性能度量分值的期望最高的行动.因此这个Agent是理性的.
##### 2)
&emsp;&emsp;如果给移动加一个代价,那么在扫地机就不能积极地进行移动.可以设计这样的一个函数:

&emsp;&emsp;当A地板是干净的,下一步移动到B地板,如果B地板也是干净的,那么就停一步,也就是在一个时间步之后再移动到A地板,如果B地板是脏的,那么就没有时间延迟.同理,如果从B地板移动到A地板后,根据环境,在之前的时间延迟之上再加一个时间步的时间延迟.

&emsp;&emsp;这样的Agent仍然是基于规则-行动的,没有复杂的内部状态,只是基于当前的环境对执行时间进行推迟,以减少移动带来的惩罚.
##### 3)
&emsp;&emsp;对于地理环境不明的情况,最好是使用随机的方式,也就是让机器自己学习到地理信息.
#### 2.3
##### a)
&emsp;&emsp;并非不可能是完全理性的,在限制条件下采取的理性也可能是完美理性的,局部最优解可能就是全局最优解.
##### b)
&emsp;&emsp;存在这样的情况,比如扫地机在需要给地面铺上沙子的任务,原来的规则就和现有的任务相悖,因此行动也会是不理性的.
##### c)
&emsp;&emsp;存在.自动驾驶任务下,每个自动驾驶的汽车都会选择当前最佳的行动.
##### d)
&emsp;&emsp;不是的,Agent程序以当前感知为输入,Agent函数以整个历史作为输入.
##### e)
&emsp;&emsp;是的,Agent函数都可以用程序/机器组合实现.
##### f)
&emsp;&emsp;不存在,完全是随机的话,就不存在最优解,那也就无法判断Agent是否是理性的.
##### g)
&emsp;&emsp;可能,任务环境不同但是相近的才能使这句话成立,因为性能度量要一致,给定的Agent才能进行任务迁移.
##### h)
&emsp;&emsp;在无法观察环境下,Agent也可能是理性的.
#### 2.5
Agent: AI的最小单元 \
Agent函数: AI行动的逻辑单元 \
Agent程序: Agent函数的实现 \
反射Agent: 基于条件-行动准则的Agent,只关注当前输入. \
基于模型的Agent: 根据过去历史维持内部状态,通过先验知识(对现实建模)和内部状态决定行动.比如自动驾驶的汽车观察到上一帧前面的车没有点亮车灯,而当前时间后车灯同时亮了,根据先验知识,可以知道前车在刹车,同样根据先验知识,得到自己也需要刹车.由此由模型和内部状态得到了减速行为. \
基于目标的Agent: 在前面的基础上加上目标信息.还是前车刹车的例子.基于目标的Agent是通过推理的形式得到,因为前车刹车了,为了不和前车相撞,我也需要刹车.也就是不同与前面是基于规则,基于目标的Agent能够推理进行决策. \
基于效用的Agent: 在上面的基础上再引入效用函数.用来评价行动和决策的分数.评价行为是否是经济,高效的. \
学习Agent: 能够实现自学习的Agent,通过Critic, Learning element, Performance element, Problem generator四个组件实现.