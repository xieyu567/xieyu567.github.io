---
title: Decision Tree
date: 2019-05-29 10:52:20
categories: 统计学习方法
tags: machine learning
mathjax: true
---
#### 决策树算法
  
决策树算法是一种简单的机器学习算法.

##### 算法步骤:
1. 如果$D$中所有实例属于同一类$C_k$,则$T$为单节点树,并将类$C_k$作为该结点的类标记.返回$T$.
2. 如果特征集$A=\varnothing$,则$T$为单节点树,并将$D$中实例数最大的类$C_k$作为该节点的类标记.返回$T$.
3. 否则,计算$A$中各特征对D的信息增益或是信息增益比,选择信息增益(信息增益比)最大的特征$A_g$.
4. 如果$A_g$的信息增益(信息增益比)小于阈值$\epsilon$,则置$T$为单节点树,并将$D$中实例数最大的类$C_k$作为该节点的类标记,返回$T$.
5. 否则,对$A_g$的每一可能值$a_i$,依$A_g=a_i$将$D$分割为若干非空子集$D_i$,将$D_i$中实例数最大的类作为标记,构建子结点,由节点及其子节点构成数$T$,返回$T$.
6. 对第$i$个子节点,以$D_i$为训练集,以$A-{A_g}$为特征集,递归地调用之前的算法,得到子树$T_i$,返回$T_i$.

<!--more-->

---
##### 信息增益和信息增益比
信息增益(也被称为互信息)的算法是:
1. 计算数据集$D$的经验熵$H(D)$
$$H(D)=-\sum^K_{k=1}\frac{|C_k|}{|D|}log_2\frac{|C_k|}{|D|}$$
2. 计算特征$A$对数据集$D$的经验条件熵$H(D|A)$
$$H(D|A)=\sum^n_{i=1}\frac{|D_i|}{|D|}H(D_i)=-\sum^n_{i=1}\frac{|D_i|}{|D|}\sum^K_{k=1}\frac{|D_{ik}|}{|D_i|}log_2\frac{|D_{ik}|}{|D_i|}$$
3. 计算信息增益
   $$g(D,A)=H(D)-H(D|A)$$

信息增益比:
$$g_R(D,A)=\frac{g(D,A)}{H_A(D)}$$